{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Bonus Stage: Model with Attention\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports we need.\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local Terms</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kopi O</td>\n",
       "      <td>Black Coffee with Sugar</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kopi</td>\n",
       "      <td>Black Coffee with Condensed Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kopi C</td>\n",
       "      <td>Black Coffee with Evaporated Milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kopi Kosong</td>\n",
       "      <td>Black Coffee without sugar or milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kopi Gah Dai</td>\n",
       "      <td>Black Coffee with extra condensed milk</td>\n",
       "      <td>https://daneshd.com/2010/02/28/a-rough-guide-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Local Terms                                 Meaning  \\\n",
       "0        Kopi O                 Black Coffee with Sugar   \n",
       "1          Kopi        Black Coffee with Condensed Milk   \n",
       "2        Kopi C       Black Coffee with Evaporated Milk   \n",
       "3   Kopi Kosong      Black Coffee without sugar or milk   \n",
       "4  Kopi Gah Dai  Black Coffee with extra condensed milk   \n",
       "\n",
       "                                              Source  \n",
       "0  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "1  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "2  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "3  https://daneshd.com/2010/02/28/a-rough-guide-t...  \n",
       "4  https://daneshd.com/2010/02/28/a-rough-guide-t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Reads the tab-delimited data using Pandas.\n",
    "kopitiam = pd.read_csv('kopitiam.tsv', sep='\\t')\n",
    "kopitiam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of reinitializing and hoping that the hashes matches, \n",
    "# we can simply load the dictionary pickle.\n",
    "\n",
    "START, START_IDX = '<s>',  0\n",
    "END, END_IDX = '</s>', 1\n",
    "UNK, UNK_IDX = 'UNK', 2 # Unknown words (currently not use in this model...)\n",
    "\n",
    "\n",
    "singlish_sents = [START] + kopitiam['Local Terms'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "english_sents = [START] + kopitiam['Meaning'].apply(str.lower).apply(word_tokenize) + [END]\n",
    "\n",
    "\"\"\"\n",
    "english_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "english_vocab.add_documents(english_sents)\n",
    "\n",
    "singlish_vocab = Dictionary([['<s>'], ['</s>'], ['UNK']])\n",
    "singlish_vocab.add_documents(singlish_sents)\n",
    "\"\"\"\n",
    "\n",
    "with open('singlish_vocab.Dictionary.pkl', 'rb') as fin:\n",
    "    singlish_vocab = pickle.load(fin)\n",
    "    \n",
    "with open('english_vocab.Dictionary.pkl', 'rb') as fin:\n",
    "    english_vocab = pickle.load(fin)\n",
    "    \n",
    "\n",
    "def vectorize_sent(sent, vocab):\n",
    "    return vocab.doc2idx([START] + word_tokenize(sent.lower()) + [END])\n",
    "\n",
    "def variable_from_sent(sent, vocab):\n",
    "    vsent = vectorize_sent(sent, vocab)\n",
    "    result = Variable(torch.LongTensor(vsent).view(-1, 1))\n",
    "    return result.cuda() if use_cuda else result\n",
    "\n",
    "# Prepare the whole training corpus.\n",
    "singlish_tensors = kopitiam['Local Terms'].apply(lambda s: variable_from_sent(s, singlish_vocab))\n",
    "english_tensors = kopitiam['Meaning'].apply(lambda s: variable_from_sent(s, english_vocab))\n",
    "\n",
    "# Now, each item in `sent_pairs` is our data point. \n",
    "sent_pairs = list(zip(singlish_tensors, english_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Decoder\n",
    "----\n",
    "\n",
    "(**Note:** the following content and code for the attention decoder are from http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called `attn_applied` in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
    "\n",
    "![](https://i.imgur.com/1152PYf.png)\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward layer `attn`, using the decoder’s input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Set the no. of nodes for the hidden layer.\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of output (i.e. no. of words in output vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        # Initialize the GRU with the \n",
    "        # - size of the hidden layer from the previous state\n",
    "        # - size of the hidden layer from the current state\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        # Set the output layer to output a specific symbol \n",
    "        # from the output vocabulary\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feed the input into the embedding layer.\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # Transform the embedded output with a relu function. \n",
    "        output = F.relu(output)\n",
    "        # Feed the embedded layer with the hidden layer to the GRU.\n",
    "        # Update the output and hidden layer.\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # Take the updated output and find the most appropriate\n",
    "        # output symbol. \n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_states(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result\n",
    "    \n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        return result.cuda() if use_cuda else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "def train_one_epoch(input_variable, target_variable, encoder, decoder, \n",
    "                    encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Function to put the variables, decoder and optimizers to train per epoch.\n",
    "    \"\"\"\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "\n",
    "    # (Re-)Initialize the optimizers, clear all gradients. \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize the length of the PyTorch variables.\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "    encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # Iterating through each word in the input.\n",
    "    for ei in range(input_length):\n",
    "        # We move forward through each state.\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        # And we save the encoder outputs. \n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input.\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # We add the encoder_outputs for attention to the decoder forward step.\n",
    "            # And expect it to return the decoder attention.\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                         decoder_hidden, \n",
    "                                                                         encoder_outputs) \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == END_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Some Logging and Plotting Candies to Monitor Training\n",
    "#########################################################\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# Top-level function to start the training,\n",
    "# iterates across epochs.\n",
    "#########################################################\n",
    "\n",
    "def train(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    training_pairs = [random.choice(sent_pairs) for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train_one_epoch(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 26m 27s) (100 0%) 3.2681\n",
      "0m 3s (- 28m 0s) (200 0%) 2.3849\n",
      "0m 4s (- 26m 27s) (300 0%) 2.2166\n",
      "0m 6s (- 25m 33s) (400 0%) 2.2512\n",
      "0m 7s (- 25m 4s) (500 0%) 2.2565\n",
      "0m 9s (- 25m 27s) (600 0%) 2.0700\n",
      "0m 10s (- 25m 13s) (700 0%) 2.1847\n",
      "0m 12s (- 24m 54s) (800 0%) 2.0570\n",
      "0m 13s (- 24m 44s) (900 0%) 2.0454\n",
      "0m 14s (- 24m 30s) (1000 1%) 1.8758\n",
      "0m 16s (- 24m 12s) (1100 1%) 1.7910\n",
      "0m 17s (- 24m 37s) (1200 1%) 1.7220\n",
      "0m 19s (- 24m 28s) (1300 1%) 1.7324\n",
      "0m 20s (- 24m 17s) (1400 1%) 1.6285\n",
      "0m 22s (- 24m 12s) (1500 1%) 1.5013\n",
      "0m 23s (- 24m 8s) (1600 1%) 1.4335\n",
      "0m 25s (- 24m 8s) (1700 1%) 1.4817\n",
      "0m 26s (- 24m 0s) (1800 1%) 1.4627\n",
      "0m 27s (- 23m 54s) (1900 1%) 1.5118\n",
      "0m 29s (- 23m 49s) (2000 2%) 1.4920\n",
      "0m 30s (- 23m 44s) (2100 2%) 1.3284\n",
      "0m 32s (- 23m 45s) (2200 2%) 1.1953\n",
      "0m 34s (- 24m 28s) (2300 2%) 1.2125\n",
      "0m 36s (- 25m 0s) (2400 2%) 1.3198\n",
      "0m 39s (- 25m 31s) (2500 2%) 1.3151\n",
      "0m 41s (- 25m 40s) (2600 2%) 1.2915\n",
      "0m 42s (- 25m 42s) (2700 2%) 1.1152\n",
      "0m 44s (- 25m 46s) (2800 2%) 1.2294\n",
      "0m 46s (- 25m 44s) (2900 2%) 1.0631\n",
      "0m 47s (- 25m 44s) (3000 3%) 1.0687\n",
      "0m 49s (- 25m 36s) (3100 3%) 1.1377\n",
      "0m 51s (- 25m 42s) (3200 3%) 1.1802\n",
      "0m 52s (- 25m 47s) (3300 3%) 0.9267\n",
      "0m 54s (- 25m 46s) (3400 3%) 0.9862\n",
      "0m 55s (- 25m 41s) (3500 3%) 0.8896\n",
      "0m 57s (- 25m 36s) (3600 3%) 1.0287\n",
      "0m 58s (- 25m 31s) (3700 3%) 1.0199\n",
      "1m 0s (- 25m 26s) (3800 3%) 0.7834\n",
      "1m 1s (- 25m 23s) (3900 3%) 0.9813\n",
      "1m 3s (- 25m 19s) (4000 4%) 1.0394\n",
      "1m 4s (- 25m 14s) (4100 4%) 1.0441\n",
      "1m 6s (- 25m 11s) (4200 4%) 0.7852\n",
      "1m 7s (- 25m 8s) (4300 4%) 0.9256\n",
      "1m 9s (- 25m 5s) (4400 4%) 0.9657\n",
      "1m 10s (- 25m 2s) (4500 4%) 0.7704\n",
      "1m 12s (- 24m 57s) (4600 4%) 0.7948\n",
      "1m 14s (- 25m 0s) (4700 4%) 0.8232\n",
      "1m 16s (- 25m 14s) (4800 4%) 0.7534\n",
      "1m 18s (- 25m 20s) (4900 4%) 0.6663\n",
      "1m 20s (- 25m 24s) (5000 5%) 0.7963\n",
      "1m 21s (- 25m 22s) (5100 5%) 0.6565\n",
      "1m 23s (- 25m 17s) (5200 5%) 0.6928\n",
      "1m 24s (- 25m 16s) (5300 5%) 0.7067\n",
      "1m 27s (- 25m 37s) (5400 5%) 0.7593\n",
      "1m 30s (- 25m 53s) (5500 5%) 0.6190\n",
      "1m 32s (- 26m 1s) (5600 5%) 0.4842\n",
      "1m 34s (- 26m 6s) (5700 5%) 0.6163\n",
      "1m 36s (- 26m 0s) (5800 5%) 0.6387\n",
      "1m 37s (- 25m 56s) (5900 5%) 0.7647\n",
      "1m 39s (- 25m 52s) (6000 6%) 0.6581\n",
      "1m 40s (- 25m 52s) (6100 6%) 0.4872\n",
      "1m 42s (- 25m 49s) (6200 6%) 0.5030\n",
      "1m 44s (- 25m 54s) (6300 6%) 0.4825\n",
      "1m 46s (- 25m 55s) (6400 6%) 0.5664\n",
      "1m 48s (- 26m 0s) (6500 6%) 0.5770\n",
      "1m 50s (- 26m 2s) (6600 6%) 0.5852\n",
      "1m 52s (- 26m 3s) (6700 6%) 0.5543\n",
      "1m 54s (- 26m 4s) (6800 6%) 0.6857\n",
      "1m 55s (- 25m 59s) (6900 6%) 0.6101\n",
      "1m 57s (- 25m 57s) (7000 7%) 0.5847\n",
      "1m 59s (- 25m 57s) (7100 7%) 0.5014\n",
      "2m 0s (- 25m 58s) (7200 7%) 0.4662\n",
      "2m 2s (- 25m 58s) (7300 7%) 0.5520\n",
      "2m 4s (- 26m 0s) (7400 7%) 0.6178\n",
      "2m 6s (- 26m 0s) (7500 7%) 0.5157\n",
      "2m 8s (- 26m 0s) (7600 7%) 0.4664\n",
      "2m 10s (- 26m 1s) (7700 7%) 0.3848\n",
      "2m 12s (- 26m 1s) (7800 7%) 0.5269\n",
      "2m 14s (- 26m 5s) (7900 7%) 0.6163\n",
      "2m 16s (- 26m 8s) (8000 8%) 0.5858\n",
      "2m 18s (- 26m 7s) (8100 8%) 0.4545\n",
      "2m 19s (- 26m 6s) (8200 8%) 0.4380\n",
      "2m 22s (- 26m 10s) (8300 8%) 0.4824\n",
      "2m 24s (- 26m 12s) (8400 8%) 0.5099\n",
      "2m 26s (- 26m 11s) (8500 8%) 0.4024\n",
      "2m 27s (- 26m 9s) (8600 8%) 0.6175\n",
      "2m 29s (- 26m 8s) (8700 8%) 0.4653\n",
      "2m 31s (- 26m 6s) (8800 8%) 0.5322\n",
      "2m 32s (- 26m 4s) (8900 8%) 0.4712\n",
      "2m 35s (- 26m 7s) (9000 9%) 0.4145\n",
      "2m 36s (- 26m 5s) (9100 9%) 0.4376\n",
      "2m 38s (- 26m 6s) (9200 9%) 0.3856\n",
      "2m 40s (- 26m 4s) (9300 9%) 0.4139\n",
      "2m 42s (- 26m 2s) (9400 9%) 0.5815\n",
      "2m 43s (- 25m 59s) (9500 9%) 0.4517\n",
      "2m 45s (- 25m 57s) (9600 9%) 0.3938\n",
      "2m 47s (- 25m 56s) (9700 9%) 0.4278\n",
      "2m 48s (- 25m 54s) (9800 9%) 0.5133\n",
      "2m 50s (- 25m 52s) (9900 9%) 0.4374\n",
      "2m 52s (- 25m 51s) (10000 10%) 0.4938\n",
      "2m 54s (- 25m 49s) (10100 10%) 0.5087\n",
      "2m 56s (- 25m 50s) (10200 10%) 0.4589\n",
      "2m 57s (- 25m 49s) (10300 10%) 0.3764\n",
      "2m 59s (- 25m 45s) (10400 10%) 0.4259\n",
      "3m 0s (- 25m 42s) (10500 10%) 0.4058\n",
      "3m 2s (- 25m 38s) (10600 10%) 0.4235\n",
      "3m 4s (- 25m 37s) (10700 10%) 0.5273\n",
      "3m 5s (- 25m 35s) (10800 10%) 0.3971\n",
      "3m 7s (- 25m 33s) (10900 10%) 0.4430\n",
      "3m 9s (- 25m 30s) (11000 11%) 0.5046\n",
      "3m 10s (- 25m 26s) (11100 11%) 0.5122\n",
      "3m 12s (- 25m 24s) (11200 11%) 0.4212\n",
      "3m 13s (- 25m 22s) (11300 11%) 0.4130\n",
      "3m 15s (- 25m 20s) (11400 11%) 0.5161\n",
      "3m 17s (- 25m 17s) (11500 11%) 0.6076\n",
      "3m 18s (- 25m 14s) (11600 11%) 0.4255\n",
      "3m 20s (- 25m 11s) (11700 11%) 0.4876\n",
      "3m 21s (- 25m 9s) (11800 11%) 0.4953\n",
      "3m 23s (- 25m 9s) (11900 11%) 0.3172\n",
      "3m 25s (- 25m 8s) (12000 12%) 0.4245\n",
      "3m 27s (- 25m 8s) (12100 12%) 0.4384\n",
      "3m 29s (- 25m 6s) (12200 12%) 0.3566\n",
      "3m 31s (- 25m 4s) (12300 12%) 0.3957\n",
      "3m 32s (- 25m 2s) (12400 12%) 0.4335\n",
      "3m 34s (- 24m 59s) (12500 12%) 0.4813\n",
      "3m 36s (- 24m 58s) (12600 12%) 0.3732\n",
      "3m 37s (- 24m 58s) (12700 12%) 0.2728\n",
      "3m 41s (- 25m 5s) (12800 12%) 0.6312\n",
      "3m 43s (- 25m 5s) (12900 12%) 0.4615\n",
      "3m 45s (- 25m 9s) (13000 13%) 0.4314\n",
      "3m 47s (- 25m 7s) (13100 13%) 0.3776\n",
      "3m 48s (- 25m 5s) (13200 13%) 0.4552\n",
      "3m 50s (- 25m 2s) (13300 13%) 0.3858\n",
      "3m 52s (- 25m 1s) (13400 13%) 0.3086\n",
      "3m 54s (- 25m 2s) (13500 13%) 0.3835\n",
      "3m 56s (- 25m 0s) (13600 13%) 0.4314\n",
      "3m 57s (- 24m 59s) (13700 13%) 0.3730\n",
      "3m 59s (- 24m 58s) (13800 13%) 0.3963\n",
      "4m 1s (- 24m 56s) (13900 13%) 0.4281\n",
      "4m 3s (- 24m 55s) (14000 14%) 0.4638\n",
      "4m 5s (- 24m 55s) (14100 14%) 0.3711\n",
      "4m 6s (- 24m 52s) (14200 14%) 0.3910\n",
      "4m 8s (- 24m 51s) (14300 14%) 0.4013\n",
      "4m 10s (- 24m 49s) (14400 14%) 0.3519\n",
      "4m 12s (- 24m 49s) (14500 14%) 0.4320\n",
      "4m 15s (- 24m 54s) (14600 14%) 0.3142\n",
      "4m 17s (- 24m 52s) (14700 14%) 0.4530\n",
      "4m 19s (- 24m 54s) (14800 14%) 0.4345\n",
      "4m 22s (- 24m 56s) (14900 14%) 0.4068\n",
      "4m 23s (- 24m 53s) (15000 15%) 0.4823\n",
      "4m 25s (- 24m 52s) (15100 15%) 0.4320\n",
      "4m 27s (- 24m 50s) (15200 15%) 0.4072\n",
      "4m 28s (- 24m 48s) (15300 15%) 0.3227\n",
      "4m 30s (- 24m 45s) (15400 15%) 0.4395\n",
      "4m 32s (- 24m 43s) (15500 15%) 0.3594\n",
      "4m 33s (- 24m 40s) (15600 15%) 0.4647\n",
      "4m 36s (- 24m 42s) (15700 15%) 0.3451\n",
      "4m 39s (- 24m 47s) (15800 15%) 0.3702\n",
      "4m 42s (- 24m 54s) (15900 15%) 0.4249\n",
      "4m 44s (- 24m 53s) (16000 16%) 0.2753\n",
      "4m 46s (- 24m 51s) (16100 16%) 0.3537\n",
      "4m 48s (- 24m 52s) (16200 16%) 0.4245\n",
      "4m 50s (- 24m 52s) (16300 16%) 0.3614\n",
      "4m 52s (- 24m 49s) (16400 16%) 0.3959\n",
      "4m 53s (- 24m 45s) (16500 16%) 0.3680\n",
      "4m 55s (- 24m 43s) (16600 16%) 0.5045\n",
      "4m 56s (- 24m 40s) (16700 16%) 0.3855\n",
      "4m 58s (- 24m 37s) (16800 16%) 0.3053\n",
      "5m 0s (- 24m 36s) (16900 16%) 0.3443\n",
      "5m 1s (- 24m 33s) (17000 17%) 0.3365\n",
      "5m 3s (- 24m 31s) (17100 17%) 0.4898\n",
      "5m 5s (- 24m 29s) (17200 17%) 0.3361\n",
      "5m 9s (- 24m 37s) (17300 17%) 0.3952\n",
      "5m 11s (- 24m 37s) (17400 17%) 0.3573\n",
      "5m 13s (- 24m 37s) (17500 17%) 0.3339\n",
      "5m 16s (- 24m 39s) (17600 17%) 0.4141\n",
      "5m 18s (- 24m 39s) (17700 17%) 0.3390\n",
      "5m 20s (- 24m 38s) (17800 17%) 0.4266\n",
      "5m 21s (- 24m 36s) (17900 17%) 0.4777\n",
      "5m 23s (- 24m 34s) (18000 18%) 0.3035\n",
      "5m 25s (- 24m 34s) (18100 18%) 0.4419\n",
      "5m 27s (- 24m 32s) (18200 18%) 0.3060\n",
      "5m 29s (- 24m 30s) (18300 18%) 0.2753\n",
      "5m 31s (- 24m 29s) (18400 18%) 0.3337\n",
      "5m 32s (- 24m 26s) (18500 18%) 0.3476\n",
      "5m 34s (- 24m 25s) (18600 18%) 0.3911\n",
      "5m 36s (- 24m 22s) (18700 18%) 0.3899\n",
      "5m 38s (- 24m 20s) (18800 18%) 0.3259\n",
      "5m 39s (- 24m 18s) (18900 18%) 0.3231\n",
      "5m 41s (- 24m 16s) (19000 19%) 0.3392\n",
      "5m 43s (- 24m 14s) (19100 19%) 0.3851\n",
      "5m 45s (- 24m 12s) (19200 19%) 0.4278\n",
      "5m 46s (- 24m 9s) (19300 19%) 0.3356\n",
      "5m 48s (- 24m 6s) (19400 19%) 0.4495\n",
      "5m 49s (- 24m 4s) (19500 19%) 0.3356\n",
      "5m 51s (- 24m 2s) (19600 19%) 0.4739\n",
      "5m 53s (- 24m 0s) (19700 19%) 0.4253\n",
      "5m 55s (- 23m 59s) (19800 19%) 0.2762\n",
      "5m 57s (- 23m 57s) (19900 19%) 0.4072\n",
      "5m 58s (- 23m 54s) (20000 20%) 0.3138\n",
      "6m 0s (- 23m 52s) (20100 20%) 0.4027\n",
      "6m 2s (- 23m 51s) (20200 20%) 0.3424\n",
      "6m 4s (- 23m 49s) (20300 20%) 0.3405\n",
      "6m 5s (- 23m 46s) (20400 20%) 0.4090\n",
      "6m 7s (- 23m 45s) (20500 20%) 0.4181\n",
      "6m 9s (- 23m 43s) (20600 20%) 0.3819\n",
      "6m 11s (- 23m 41s) (20700 20%) 0.2791\n",
      "6m 12s (- 23m 38s) (20800 20%) 0.3316\n",
      "6m 14s (- 23m 37s) (20900 20%) 0.3251\n",
      "6m 16s (- 23m 36s) (21000 21%) 0.4142\n",
      "6m 18s (- 23m 34s) (21100 21%) 0.3924\n",
      "6m 20s (- 23m 32s) (21200 21%) 0.3366\n",
      "6m 21s (- 23m 30s) (21300 21%) 0.4042\n",
      "6m 24s (- 23m 30s) (21400 21%) 0.3250\n",
      "6m 25s (- 23m 29s) (21500 21%) 0.3739\n",
      "6m 27s (- 23m 26s) (21600 21%) 0.4066\n",
      "6m 29s (- 23m 24s) (21700 21%) 0.3308\n",
      "6m 30s (- 23m 20s) (21800 21%) 0.3882\n",
      "6m 32s (- 23m 18s) (21900 21%) 0.3726\n",
      "6m 33s (- 23m 15s) (22000 22%) 0.4303\n",
      "6m 35s (- 23m 13s) (22100 22%) 0.4386\n",
      "6m 37s (- 23m 11s) (22200 22%) 0.3504\n",
      "6m 38s (- 23m 9s) (22300 22%) 0.3632\n",
      "6m 40s (- 23m 7s) (22400 22%) 0.4347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 42s (- 23m 5s) (22500 22%) 0.2937\n",
      "6m 44s (- 23m 5s) (22600 22%) 0.3780\n",
      "6m 46s (- 23m 3s) (22700 22%) 0.2737\n",
      "6m 48s (- 23m 1s) (22800 22%) 0.4909\n",
      "6m 49s (- 23m 0s) (22900 22%) 0.3049\n",
      "6m 51s (- 22m 57s) (23000 23%) 0.4517\n",
      "6m 53s (- 22m 56s) (23100 23%) 0.3892\n",
      "6m 55s (- 22m 54s) (23200 23%) 0.2867\n",
      "6m 56s (- 22m 51s) (23300 23%) 0.2874\n",
      "6m 58s (- 22m 49s) (23400 23%) 0.3210\n",
      "6m 59s (- 22m 47s) (23500 23%) 0.3822\n",
      "7m 1s (- 22m 45s) (23600 23%) 0.3622\n",
      "7m 3s (- 22m 42s) (23700 23%) 0.3289\n",
      "7m 4s (- 22m 40s) (23800 23%) 0.2977\n",
      "7m 6s (- 22m 39s) (23900 23%) 0.4064\n",
      "7m 8s (- 22m 37s) (24000 24%) 0.3294\n",
      "7m 10s (- 22m 35s) (24100 24%) 0.4370\n",
      "7m 11s (- 22m 32s) (24200 24%) 0.3622\n",
      "7m 13s (- 22m 30s) (24300 24%) 0.3257\n",
      "7m 15s (- 22m 28s) (24400 24%) 0.2928\n",
      "7m 16s (- 22m 26s) (24500 24%) 0.3497\n",
      "7m 18s (- 22m 23s) (24600 24%) 0.3398\n",
      "7m 19s (- 22m 21s) (24700 24%) 0.4039\n",
      "7m 21s (- 22m 18s) (24800 24%) 0.4295\n",
      "7m 23s (- 22m 16s) (24900 24%) 0.3952\n",
      "7m 24s (- 22m 13s) (25000 25%) 0.5070\n",
      "7m 26s (- 22m 11s) (25100 25%) 0.2843\n",
      "7m 27s (- 22m 9s) (25200 25%) 0.3260\n",
      "7m 29s (- 22m 7s) (25300 25%) 0.3195\n",
      "7m 31s (- 22m 4s) (25400 25%) 0.2919\n",
      "7m 32s (- 22m 2s) (25500 25%) 0.2965\n",
      "7m 34s (- 22m 0s) (25600 25%) 0.3189\n",
      "7m 36s (- 21m 58s) (25700 25%) 0.3828\n",
      "7m 38s (- 21m 58s) (25800 25%) 0.4695\n",
      "7m 40s (- 21m 57s) (25900 25%) 0.3636\n",
      "7m 42s (- 21m 55s) (26000 26%) 0.3361\n",
      "7m 44s (- 21m 54s) (26100 26%) 0.3634\n",
      "7m 46s (- 21m 52s) (26200 26%) 0.3472\n",
      "7m 47s (- 21m 50s) (26300 26%) 0.2948\n",
      "7m 49s (- 21m 49s) (26400 26%) 0.4307\n",
      "7m 51s (- 21m 47s) (26500 26%) 0.3532\n",
      "7m 53s (- 21m 46s) (26600 26%) 0.3473\n",
      "7m 55s (- 21m 44s) (26700 26%) 0.2807\n",
      "7m 56s (- 21m 42s) (26800 26%) 0.3265\n",
      "7m 58s (- 21m 41s) (26900 26%) 0.4236\n",
      "8m 0s (- 21m 38s) (27000 27%) 0.3560\n",
      "8m 1s (- 21m 36s) (27100 27%) 0.3273\n",
      "8m 3s (- 21m 33s) (27200 27%) 0.3310\n",
      "8m 5s (- 21m 31s) (27300 27%) 0.3202\n",
      "8m 7s (- 21m 31s) (27400 27%) 0.3139\n",
      "8m 9s (- 21m 30s) (27500 27%) 0.2881\n",
      "8m 11s (- 21m 28s) (27600 27%) 0.2530\n",
      "8m 12s (- 21m 25s) (27700 27%) 0.3014\n",
      "8m 14s (- 21m 23s) (27800 27%) 0.2819\n",
      "8m 15s (- 21m 21s) (27900 27%) 0.2822\n",
      "8m 17s (- 21m 19s) (28000 28%) 0.2873\n",
      "8m 19s (- 21m 17s) (28100 28%) 0.2954\n",
      "8m 21s (- 21m 15s) (28200 28%) 0.3858\n",
      "8m 22s (- 21m 13s) (28300 28%) 0.3838\n",
      "8m 24s (- 21m 11s) (28400 28%) 0.4243\n",
      "8m 26s (- 21m 10s) (28500 28%) 0.3870\n",
      "8m 27s (- 21m 7s) (28600 28%) 0.3523\n",
      "8m 30s (- 21m 8s) (28700 28%) 0.3824\n",
      "8m 32s (- 21m 7s) (28800 28%) 0.2929\n",
      "8m 34s (- 21m 5s) (28900 28%) 0.3930\n",
      "8m 36s (- 21m 3s) (29000 28%) 0.2944\n",
      "8m 38s (- 21m 2s) (29100 29%) 0.2705\n",
      "8m 40s (- 21m 1s) (29200 29%) 0.3111\n",
      "8m 42s (- 20m 59s) (29300 29%) 0.2824\n",
      "8m 43s (- 20m 57s) (29400 29%) 0.4099\n",
      "8m 45s (- 20m 55s) (29500 29%) 0.3204\n",
      "8m 47s (- 20m 54s) (29600 29%) 0.3572\n",
      "8m 49s (- 20m 52s) (29700 29%) 0.3451\n",
      "8m 50s (- 20m 49s) (29800 29%) 0.3156\n",
      "8m 52s (- 20m 48s) (29900 29%) 0.4105\n",
      "8m 54s (- 20m 47s) (30000 30%) 0.3316\n",
      "8m 56s (- 20m 45s) (30100 30%) 0.4193\n",
      "8m 57s (- 20m 43s) (30200 30%) 0.3075\n",
      "8m 59s (- 20m 41s) (30300 30%) 0.3429\n",
      "9m 1s (- 20m 39s) (30400 30%) 0.3672\n",
      "9m 2s (- 20m 36s) (30500 30%) 0.4020\n",
      "9m 4s (- 20m 34s) (30600 30%) 0.2946\n",
      "9m 5s (- 20m 32s) (30700 30%) 0.3358\n",
      "9m 7s (- 20m 30s) (30800 30%) 0.4234\n",
      "9m 9s (- 20m 28s) (30900 30%) 0.3592\n",
      "9m 10s (- 20m 26s) (31000 31%) 0.3705\n",
      "9m 12s (- 20m 23s) (31100 31%) 0.3339\n",
      "9m 14s (- 20m 22s) (31200 31%) 0.4482\n",
      "9m 15s (- 20m 19s) (31300 31%) 0.3597\n",
      "9m 17s (- 20m 17s) (31400 31%) 0.3196\n",
      "9m 18s (- 20m 15s) (31500 31%) 0.4143\n",
      "9m 20s (- 20m 13s) (31600 31%) 0.4428\n",
      "9m 22s (- 20m 11s) (31700 31%) 0.3352\n",
      "9m 24s (- 20m 11s) (31800 31%) 0.3051\n",
      "9m 27s (- 20m 11s) (31900 31%) 0.3232\n",
      "9m 29s (- 20m 9s) (32000 32%) 0.3288\n",
      "9m 30s (- 20m 7s) (32100 32%) 0.3121\n",
      "9m 32s (- 20m 5s) (32200 32%) 0.3190\n",
      "9m 34s (- 20m 3s) (32300 32%) 0.4820\n",
      "9m 35s (- 20m 0s) (32400 32%) 0.3800\n",
      "9m 37s (- 19m 58s) (32500 32%) 0.2594\n",
      "9m 38s (- 19m 56s) (32600 32%) 0.4054\n",
      "9m 40s (- 19m 54s) (32700 32%) 0.3845\n",
      "9m 42s (- 19m 52s) (32800 32%) 0.2763\n",
      "9m 44s (- 19m 51s) (32900 32%) 0.2691\n",
      "9m 45s (- 19m 48s) (33000 33%) 0.3695\n",
      "9m 47s (- 19m 46s) (33100 33%) 0.3354\n",
      "9m 48s (- 19m 44s) (33200 33%) 0.3355\n",
      "9m 50s (- 19m 42s) (33300 33%) 0.3436\n",
      "9m 51s (- 19m 40s) (33400 33%) 0.4029\n",
      "9m 53s (- 19m 37s) (33500 33%) 0.3182\n",
      "9m 54s (- 19m 35s) (33600 33%) 0.2642\n",
      "9m 56s (- 19m 33s) (33700 33%) 0.4422\n",
      "9m 57s (- 19m 31s) (33800 33%) 0.3201\n",
      "9m 59s (- 19m 28s) (33900 33%) 0.3334\n",
      "10m 1s (- 19m 26s) (34000 34%) 0.3527\n",
      "10m 2s (- 19m 24s) (34100 34%) 0.2879\n",
      "10m 3s (- 19m 22s) (34200 34%) 0.3198\n",
      "10m 5s (- 19m 19s) (34300 34%) 0.3267\n",
      "10m 7s (- 19m 19s) (34400 34%) 0.3131\n",
      "10m 9s (- 19m 18s) (34500 34%) 0.3191\n",
      "10m 12s (- 19m 18s) (34600 34%) 0.3702\n",
      "10m 15s (- 19m 17s) (34700 34%) 0.4214\n",
      "10m 17s (- 19m 16s) (34800 34%) 0.3738\n",
      "10m 19s (- 19m 14s) (34900 34%) 0.3290\n",
      "10m 20s (- 19m 13s) (35000 35%) 0.2757\n",
      "10m 22s (- 19m 11s) (35100 35%) 0.3558\n",
      "10m 24s (- 19m 9s) (35200 35%) 0.3099\n",
      "10m 26s (- 19m 7s) (35300 35%) 0.3399\n",
      "10m 28s (- 19m 6s) (35400 35%) 0.3856\n",
      "10m 30s (- 19m 5s) (35500 35%) 0.4020\n",
      "10m 32s (- 19m 4s) (35600 35%) 0.3258\n",
      "10m 34s (- 19m 3s) (35700 35%) 0.3381\n",
      "10m 36s (- 19m 1s) (35800 35%) 0.4004\n",
      "10m 38s (- 18m 59s) (35900 35%) 0.3436\n",
      "10m 39s (- 18m 57s) (36000 36%) 0.3202\n",
      "10m 41s (- 18m 55s) (36100 36%) 0.3483\n",
      "10m 42s (- 18m 52s) (36200 36%) 0.3107\n",
      "10m 44s (- 18m 50s) (36300 36%) 0.3981\n",
      "10m 45s (- 18m 47s) (36400 36%) 0.3043\n",
      "10m 46s (- 18m 45s) (36500 36%) 0.3897\n",
      "10m 48s (- 18m 42s) (36600 36%) 0.2551\n",
      "10m 49s (- 18m 40s) (36700 36%) 0.3476\n",
      "10m 51s (- 18m 39s) (36800 36%) 0.3781\n",
      "10m 54s (- 18m 38s) (36900 36%) 0.4323\n",
      "10m 55s (- 18m 36s) (37000 37%) 0.3717\n",
      "10m 57s (- 18m 35s) (37100 37%) 0.2812\n",
      "10m 59s (- 18m 34s) (37200 37%) 0.3748\n",
      "11m 2s (- 18m 33s) (37300 37%) 0.2904\n",
      "11m 4s (- 18m 31s) (37400 37%) 0.3130\n",
      "11m 6s (- 18m 30s) (37500 37%) 0.3245\n",
      "11m 8s (- 18m 29s) (37600 37%) 0.4276\n",
      "11m 11s (- 18m 30s) (37700 37%) 0.2903\n",
      "11m 14s (- 18m 29s) (37800 37%) 0.3376\n",
      "11m 16s (- 18m 28s) (37900 37%) 0.4011\n",
      "11m 18s (- 18m 26s) (38000 38%) 0.4005\n",
      "11m 21s (- 18m 26s) (38100 38%) 0.4470\n",
      "11m 23s (- 18m 25s) (38200 38%) 0.3114\n",
      "11m 26s (- 18m 25s) (38300 38%) 0.3968\n",
      "11m 28s (- 18m 23s) (38400 38%) 0.2828\n",
      "11m 30s (- 18m 22s) (38500 38%) 0.3494\n",
      "11m 31s (- 18m 20s) (38600 38%) 0.3772\n",
      "11m 34s (- 18m 19s) (38700 38%) 0.3311\n",
      "11m 36s (- 18m 18s) (38800 38%) 0.3241\n",
      "11m 38s (- 18m 16s) (38900 38%) 0.3644\n",
      "11m 40s (- 18m 15s) (39000 39%) 0.3797\n",
      "11m 42s (- 18m 14s) (39100 39%) 0.3628\n",
      "11m 44s (- 18m 12s) (39200 39%) 0.3311\n",
      "11m 45s (- 18m 9s) (39300 39%) 0.3896\n",
      "11m 46s (- 18m 7s) (39400 39%) 0.4033\n",
      "11m 48s (- 18m 4s) (39500 39%) 0.3060\n",
      "11m 49s (- 18m 2s) (39600 39%) 0.3040\n",
      "11m 51s (- 18m 0s) (39700 39%) 0.3046\n",
      "11m 52s (- 17m 57s) (39800 39%) 0.5129\n",
      "11m 54s (- 17m 55s) (39900 39%) 0.3534\n",
      "11m 55s (- 17m 53s) (40000 40%) 0.2650\n",
      "11m 57s (- 17m 51s) (40100 40%) 0.2559\n",
      "11m 58s (- 17m 49s) (40200 40%) 0.3337\n",
      "12m 0s (- 17m 46s) (40300 40%) 0.4015\n",
      "12m 1s (- 17m 44s) (40400 40%) 0.3611\n",
      "12m 3s (- 17m 42s) (40500 40%) 0.3653\n",
      "12m 4s (- 17m 39s) (40600 40%) 0.3459\n",
      "12m 5s (- 17m 37s) (40700 40%) 0.4075\n",
      "12m 7s (- 17m 34s) (40800 40%) 0.3050\n",
      "12m 8s (- 17m 32s) (40900 40%) 0.3721\n",
      "12m 9s (- 17m 30s) (41000 41%) 0.4304\n",
      "12m 11s (- 17m 27s) (41100 41%) 0.3845\n",
      "12m 12s (- 17m 25s) (41200 41%) 0.3599\n",
      "12m 14s (- 17m 23s) (41300 41%) 0.3522\n",
      "12m 15s (- 17m 20s) (41400 41%) 0.4082\n",
      "12m 16s (- 17m 18s) (41500 41%) 0.3951\n",
      "12m 18s (- 17m 16s) (41600 41%) 0.3196\n",
      "12m 19s (- 17m 14s) (41700 41%) 0.3386\n",
      "12m 21s (- 17m 11s) (41800 41%) 0.3116\n",
      "12m 22s (- 17m 9s) (41900 41%) 0.4399\n",
      "12m 23s (- 17m 7s) (42000 42%) 0.4784\n",
      "12m 25s (- 17m 4s) (42100 42%) 0.3178\n",
      "12m 26s (- 17m 2s) (42200 42%) 0.3732\n",
      "12m 27s (- 17m 0s) (42300 42%) 0.2982\n",
      "12m 29s (- 16m 57s) (42400 42%) 0.4145\n",
      "12m 30s (- 16m 55s) (42500 42%) 0.3519\n",
      "12m 32s (- 16m 53s) (42600 42%) 0.3731\n",
      "12m 33s (- 16m 50s) (42700 42%) 0.3029\n",
      "12m 34s (- 16m 48s) (42800 42%) 0.2488\n",
      "12m 36s (- 16m 46s) (42900 42%) 0.2845\n",
      "12m 37s (- 16m 44s) (43000 43%) 0.4316\n",
      "12m 38s (- 16m 41s) (43100 43%) 0.3104\n",
      "12m 40s (- 16m 39s) (43200 43%) 0.3890\n",
      "12m 41s (- 16m 37s) (43300 43%) 0.2874\n",
      "12m 43s (- 16m 35s) (43400 43%) 0.4659\n",
      "12m 44s (- 16m 32s) (43500 43%) 0.2972\n",
      "12m 45s (- 16m 30s) (43600 43%) 0.2959\n",
      "12m 47s (- 16m 28s) (43700 43%) 0.3451\n",
      "12m 48s (- 16m 25s) (43800 43%) 0.2967\n",
      "12m 49s (- 16m 23s) (43900 43%) 0.4096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12m 51s (- 16m 21s) (44000 44%) 0.2892\n",
      "12m 52s (- 16m 18s) (44100 44%) 0.3978\n",
      "12m 53s (- 16m 16s) (44200 44%) 0.4015\n",
      "12m 55s (- 16m 14s) (44300 44%) 0.3424\n",
      "12m 56s (- 16m 12s) (44400 44%) 0.3380\n",
      "12m 58s (- 16m 10s) (44500 44%) 0.3093\n",
      "12m 59s (- 16m 8s) (44600 44%) 0.3525\n",
      "13m 1s (- 16m 6s) (44700 44%) 0.3696\n",
      "13m 2s (- 16m 4s) (44800 44%) 0.3497\n",
      "13m 4s (- 16m 2s) (44900 44%) 0.3569\n",
      "13m 5s (- 15m 59s) (45000 45%) 0.3904\n",
      "13m 6s (- 15m 57s) (45100 45%) 0.2916\n",
      "13m 8s (- 15m 55s) (45200 45%) 0.3776\n",
      "13m 9s (- 15m 53s) (45300 45%) 0.3403\n",
      "13m 10s (- 15m 50s) (45400 45%) 0.3516\n",
      "13m 12s (- 15m 48s) (45500 45%) 0.3621\n",
      "13m 13s (- 15m 46s) (45600 45%) 0.3841\n",
      "13m 14s (- 15m 44s) (45700 45%) 0.3541\n",
      "13m 16s (- 15m 42s) (45800 45%) 0.3647\n",
      "13m 17s (- 15m 39s) (45900 45%) 0.4593\n",
      "13m 18s (- 15m 37s) (46000 46%) 0.3727\n",
      "13m 20s (- 15m 35s) (46100 46%) 0.3205\n",
      "13m 21s (- 15m 33s) (46200 46%) 0.3516\n",
      "13m 22s (- 15m 31s) (46300 46%) 0.3579\n",
      "13m 24s (- 15m 29s) (46400 46%) 0.3195\n",
      "13m 25s (- 15m 27s) (46500 46%) 0.3646\n",
      "13m 27s (- 15m 25s) (46600 46%) 0.3282\n",
      "13m 28s (- 15m 22s) (46700 46%) 0.3669\n",
      "13m 29s (- 15m 20s) (46800 46%) 0.2695\n",
      "13m 31s (- 15m 18s) (46900 46%) 0.2316\n",
      "13m 32s (- 15m 16s) (47000 47%) 0.2975\n",
      "13m 34s (- 15m 14s) (47100 47%) 0.2735\n",
      "13m 35s (- 15m 12s) (47200 47%) 0.3400\n",
      "13m 36s (- 15m 9s) (47300 47%) 0.2942\n",
      "13m 38s (- 15m 7s) (47400 47%) 0.3307\n",
      "13m 39s (- 15m 5s) (47500 47%) 0.3755\n",
      "13m 41s (- 15m 3s) (47600 47%) 0.3156\n",
      "13m 42s (- 15m 1s) (47700 47%) 0.3886\n",
      "13m 43s (- 14m 59s) (47800 47%) 0.3480\n",
      "13m 45s (- 14m 57s) (47900 47%) 0.3724\n",
      "13m 46s (- 14m 55s) (48000 48%) 0.3206\n",
      "13m 47s (- 14m 53s) (48100 48%) 0.3789\n",
      "13m 49s (- 14m 51s) (48200 48%) 0.3586\n",
      "13m 50s (- 14m 48s) (48300 48%) 0.3794\n",
      "13m 51s (- 14m 46s) (48400 48%) 0.3175\n",
      "13m 53s (- 14m 44s) (48500 48%) 0.3550\n",
      "13m 54s (- 14m 42s) (48600 48%) 0.3411\n",
      "13m 55s (- 14m 40s) (48700 48%) 0.3414\n",
      "13m 57s (- 14m 38s) (48800 48%) 0.3311\n",
      "13m 58s (- 14m 36s) (48900 48%) 0.2997\n",
      "14m 0s (- 14m 34s) (49000 49%) 0.4009\n",
      "14m 1s (- 14m 32s) (49100 49%) 0.3516\n",
      "14m 2s (- 14m 30s) (49200 49%) 0.3317\n",
      "14m 4s (- 14m 28s) (49300 49%) 0.2405\n",
      "14m 5s (- 14m 26s) (49400 49%) 0.3241\n",
      "14m 7s (- 14m 24s) (49500 49%) 0.3622\n",
      "14m 9s (- 14m 22s) (49600 49%) 0.2712\n",
      "14m 10s (- 14m 20s) (49700 49%) 0.3292\n",
      "14m 12s (- 14m 19s) (49800 49%) 0.3536\n",
      "14m 14s (- 14m 17s) (49900 49%) 0.3278\n",
      "14m 15s (- 14m 15s) (50000 50%) 0.4122\n",
      "14m 17s (- 14m 13s) (50100 50%) 0.3265\n",
      "14m 18s (- 14m 11s) (50200 50%) 0.2435\n",
      "14m 20s (- 14m 9s) (50300 50%) 0.3332\n",
      "14m 22s (- 14m 8s) (50400 50%) 0.3955\n",
      "14m 23s (- 14m 6s) (50500 50%) 0.3661\n",
      "14m 24s (- 14m 4s) (50600 50%) 0.2986\n",
      "14m 26s (- 14m 2s) (50700 50%) 0.3600\n",
      "14m 27s (- 14m 0s) (50800 50%) 0.3843\n",
      "14m 28s (- 13m 58s) (50900 50%) 0.3396\n",
      "14m 30s (- 13m 56s) (51000 51%) 0.4066\n",
      "14m 31s (- 13m 54s) (51100 51%) 0.2714\n",
      "14m 32s (- 13m 52s) (51200 51%) 0.3785\n",
      "14m 34s (- 13m 49s) (51300 51%) 0.3290\n",
      "14m 35s (- 13m 47s) (51400 51%) 0.2123\n",
      "14m 37s (- 13m 45s) (51500 51%) 0.2116\n",
      "14m 38s (- 13m 44s) (51600 51%) 0.2822\n",
      "14m 39s (- 13m 42s) (51700 51%) 0.3834\n",
      "14m 41s (- 13m 40s) (51800 51%) 0.3382\n",
      "14m 42s (- 13m 38s) (51900 51%) 0.3169\n",
      "14m 44s (- 13m 36s) (52000 52%) 0.4196\n",
      "14m 46s (- 13m 34s) (52100 52%) 0.3720\n",
      "14m 47s (- 13m 32s) (52200 52%) 0.3298\n",
      "14m 49s (- 13m 30s) (52300 52%) 0.3866\n",
      "14m 50s (- 13m 28s) (52400 52%) 0.2998\n",
      "14m 51s (- 13m 26s) (52500 52%) 0.3572\n",
      "14m 53s (- 13m 24s) (52600 52%) 0.3716\n",
      "14m 54s (- 13m 22s) (52700 52%) 0.3727\n",
      "14m 56s (- 13m 20s) (52800 52%) 0.2789\n",
      "14m 57s (- 13m 19s) (52900 52%) 0.2735\n",
      "14m 58s (- 13m 16s) (53000 53%) 0.3270\n",
      "15m 0s (- 13m 15s) (53100 53%) 0.3818\n",
      "15m 1s (- 13m 13s) (53200 53%) 0.3647\n",
      "15m 2s (- 13m 11s) (53300 53%) 0.3597\n",
      "15m 4s (- 13m 9s) (53400 53%) 0.3275\n",
      "15m 5s (- 13m 7s) (53500 53%) 0.3766\n",
      "15m 6s (- 13m 4s) (53600 53%) 0.2075\n",
      "15m 8s (- 13m 3s) (53700 53%) 0.3066\n",
      "15m 9s (- 13m 0s) (53800 53%) 0.2897\n",
      "15m 10s (- 12m 58s) (53900 53%) 0.3098\n",
      "15m 12s (- 12m 56s) (54000 54%) 0.2928\n",
      "15m 13s (- 12m 55s) (54100 54%) 0.2976\n",
      "15m 14s (- 12m 53s) (54200 54%) 0.3026\n",
      "15m 16s (- 12m 51s) (54300 54%) 0.3004\n",
      "15m 17s (- 12m 49s) (54400 54%) 0.3200\n",
      "15m 18s (- 12m 47s) (54500 54%) 0.3331\n",
      "15m 20s (- 12m 45s) (54600 54%) 0.3156\n",
      "15m 21s (- 12m 43s) (54700 54%) 0.2840\n",
      "15m 22s (- 12m 41s) (54800 54%) 0.2526\n",
      "15m 24s (- 12m 39s) (54900 54%) 0.3453\n",
      "15m 25s (- 12m 37s) (55000 55%) 0.3964\n",
      "15m 27s (- 12m 35s) (55100 55%) 0.3155\n",
      "15m 28s (- 12m 33s) (55200 55%) 0.3615\n",
      "15m 29s (- 12m 31s) (55300 55%) 0.3093\n",
      "15m 31s (- 12m 29s) (55400 55%) 0.3024\n",
      "15m 32s (- 12m 27s) (55500 55%) 0.3087\n",
      "15m 34s (- 12m 25s) (55600 55%) 0.3549\n",
      "15m 35s (- 12m 24s) (55700 55%) 0.4047\n",
      "15m 37s (- 12m 22s) (55800 55%) 0.3584\n",
      "15m 39s (- 12m 21s) (55900 55%) 0.2487\n",
      "15m 41s (- 12m 19s) (56000 56%) 0.3161\n",
      "15m 42s (- 12m 17s) (56100 56%) 0.3660\n",
      "15m 44s (- 12m 15s) (56200 56%) 0.2394\n",
      "15m 45s (- 12m 14s) (56300 56%) 0.3410\n",
      "15m 47s (- 12m 12s) (56400 56%) 0.3775\n",
      "15m 48s (- 12m 10s) (56500 56%) 0.2734\n",
      "15m 49s (- 12m 8s) (56600 56%) 0.4289\n",
      "15m 51s (- 12m 6s) (56700 56%) 0.3170\n",
      "15m 52s (- 12m 4s) (56800 56%) 0.3556\n",
      "15m 54s (- 12m 2s) (56900 56%) 0.3361\n",
      "15m 55s (- 12m 0s) (57000 56%) 0.3446\n",
      "15m 56s (- 11m 58s) (57100 57%) 0.2989\n",
      "15m 58s (- 11m 57s) (57200 57%) 0.3497\n",
      "15m 59s (- 11m 55s) (57300 57%) 0.2925\n",
      "16m 1s (- 11m 53s) (57400 57%) 0.3101\n",
      "16m 2s (- 11m 51s) (57500 57%) 0.3203\n",
      "16m 3s (- 11m 49s) (57600 57%) 0.3200\n",
      "16m 5s (- 11m 47s) (57700 57%) 0.3054\n",
      "16m 6s (- 11m 45s) (57800 57%) 0.3771\n",
      "16m 7s (- 11m 43s) (57900 57%) 0.2633\n",
      "16m 9s (- 11m 41s) (58000 57%) 0.3552\n",
      "16m 10s (- 11m 39s) (58100 58%) 0.4345\n",
      "16m 12s (- 11m 38s) (58200 58%) 0.3422\n",
      "16m 13s (- 11m 36s) (58300 58%) 0.2551\n",
      "16m 14s (- 11m 34s) (58400 58%) 0.3573\n",
      "16m 16s (- 11m 32s) (58500 58%) 0.2989\n",
      "16m 17s (- 11m 30s) (58600 58%) 0.3497\n",
      "16m 18s (- 11m 28s) (58700 58%) 0.2809\n",
      "16m 20s (- 11m 26s) (58800 58%) 0.3287\n",
      "16m 21s (- 11m 24s) (58900 58%) 0.3372\n",
      "16m 23s (- 11m 23s) (59000 59%) 0.4727\n",
      "16m 24s (- 11m 21s) (59100 59%) 0.2985\n",
      "16m 25s (- 11m 19s) (59200 59%) 0.3680\n",
      "16m 27s (- 11m 17s) (59300 59%) 0.3398\n",
      "16m 28s (- 11m 15s) (59400 59%) 0.2708\n",
      "16m 30s (- 11m 13s) (59500 59%) 0.2674\n",
      "16m 31s (- 11m 12s) (59600 59%) 0.4092\n",
      "16m 32s (- 11m 10s) (59700 59%) 0.3705\n",
      "16m 34s (- 11m 8s) (59800 59%) 0.3594\n",
      "16m 35s (- 11m 6s) (59900 59%) 0.2942\n",
      "16m 37s (- 11m 4s) (60000 60%) 0.3496\n",
      "16m 38s (- 11m 2s) (60100 60%) 0.3554\n",
      "16m 40s (- 11m 1s) (60200 60%) 0.3266\n",
      "16m 41s (- 10m 59s) (60300 60%) 0.3012\n",
      "16m 42s (- 10m 57s) (60400 60%) 0.3468\n",
      "16m 44s (- 10m 55s) (60500 60%) 0.3229\n",
      "16m 45s (- 10m 53s) (60600 60%) 0.3761\n",
      "16m 47s (- 10m 52s) (60700 60%) 0.3471\n",
      "16m 48s (- 10m 50s) (60800 60%) 0.4653\n",
      "16m 50s (- 10m 48s) (60900 60%) 0.3306\n",
      "16m 51s (- 10m 46s) (61000 61%) 0.3611\n",
      "16m 52s (- 10m 44s) (61100 61%) 0.3237\n",
      "16m 54s (- 10m 42s) (61200 61%) 0.3443\n",
      "16m 55s (- 10m 41s) (61300 61%) 0.2849\n",
      "16m 57s (- 10m 39s) (61400 61%) 0.4660\n",
      "16m 58s (- 10m 37s) (61500 61%) 0.2648\n",
      "17m 0s (- 10m 36s) (61600 61%) 0.4617\n",
      "17m 2s (- 10m 34s) (61700 61%) 0.2800\n",
      "17m 4s (- 10m 33s) (61800 61%) 0.3582\n",
      "17m 5s (- 10m 31s) (61900 61%) 0.3904\n",
      "17m 7s (- 10m 29s) (62000 62%) 0.3613\n",
      "17m 8s (- 10m 27s) (62100 62%) 0.2834\n",
      "17m 9s (- 10m 25s) (62200 62%) 0.3433\n",
      "17m 11s (- 10m 23s) (62300 62%) 0.4280\n",
      "17m 12s (- 10m 22s) (62400 62%) 0.3659\n",
      "17m 13s (- 10m 20s) (62500 62%) 0.3463\n",
      "17m 15s (- 10m 18s) (62600 62%) 0.2368\n",
      "17m 16s (- 10m 16s) (62700 62%) 0.3481\n",
      "17m 18s (- 10m 15s) (62800 62%) 0.3457\n",
      "17m 19s (- 10m 13s) (62900 62%) 0.3875\n",
      "17m 21s (- 10m 11s) (63000 63%) 0.3156\n",
      "17m 22s (- 10m 9s) (63100 63%) 0.2583\n",
      "17m 23s (- 10m 7s) (63200 63%) 0.3355\n",
      "17m 25s (- 10m 6s) (63300 63%) 0.2844\n",
      "17m 26s (- 10m 4s) (63400 63%) 0.3597\n",
      "17m 28s (- 10m 2s) (63500 63%) 0.2488\n",
      "17m 29s (- 10m 0s) (63600 63%) 0.3492\n",
      "17m 30s (- 9m 58s) (63700 63%) 0.3091\n",
      "17m 32s (- 9m 57s) (63800 63%) 0.3157\n",
      "17m 33s (- 9m 55s) (63900 63%) 0.4785\n",
      "17m 35s (- 9m 53s) (64000 64%) 0.3688\n",
      "17m 36s (- 9m 51s) (64100 64%) 0.3563\n",
      "17m 37s (- 9m 49s) (64200 64%) 0.3487\n",
      "17m 39s (- 9m 47s) (64300 64%) 0.3138\n",
      "17m 40s (- 9m 46s) (64400 64%) 0.2941\n",
      "17m 41s (- 9m 44s) (64500 64%) 0.3421\n",
      "17m 43s (- 9m 42s) (64600 64%) 0.2980\n",
      "17m 44s (- 9m 40s) (64700 64%) 0.2764\n",
      "17m 46s (- 9m 39s) (64800 64%) 0.3408\n",
      "17m 47s (- 9m 37s) (64900 64%) 0.3191\n",
      "17m 48s (- 9m 35s) (65000 65%) 0.3425\n",
      "17m 50s (- 9m 33s) (65100 65%) 0.2695\n",
      "17m 51s (- 9m 31s) (65200 65%) 0.2808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17m 52s (- 9m 30s) (65300 65%) 0.3401\n",
      "17m 54s (- 9m 28s) (65400 65%) 0.3663\n",
      "17m 55s (- 9m 26s) (65500 65%) 0.3955\n",
      "17m 57s (- 9m 24s) (65600 65%) 0.3890\n",
      "17m 58s (- 9m 22s) (65700 65%) 0.2427\n",
      "17m 59s (- 9m 21s) (65800 65%) 0.4044\n",
      "18m 1s (- 9m 19s) (65900 65%) 0.2719\n",
      "18m 2s (- 9m 17s) (66000 66%) 0.3753\n",
      "18m 4s (- 9m 16s) (66100 66%) 0.3541\n",
      "18m 5s (- 9m 14s) (66200 66%) 0.3373\n",
      "18m 6s (- 9m 12s) (66300 66%) 0.3431\n",
      "18m 8s (- 9m 10s) (66400 66%) 0.2559\n",
      "18m 9s (- 9m 8s) (66500 66%) 0.2783\n",
      "18m 10s (- 9m 6s) (66600 66%) 0.3343\n",
      "18m 12s (- 9m 5s) (66700 66%) 0.4015\n",
      "18m 13s (- 9m 3s) (66800 66%) 0.2483\n",
      "18m 14s (- 9m 1s) (66900 66%) 0.3127\n",
      "18m 16s (- 8m 59s) (67000 67%) 0.2873\n",
      "18m 17s (- 8m 58s) (67100 67%) 0.3049\n",
      "18m 18s (- 8m 56s) (67200 67%) 0.2873\n",
      "18m 20s (- 8m 54s) (67300 67%) 0.3042\n",
      "18m 21s (- 8m 52s) (67400 67%) 0.3032\n",
      "18m 23s (- 8m 51s) (67500 67%) 0.3399\n",
      "18m 25s (- 8m 49s) (67600 67%) 0.3107\n",
      "18m 27s (- 8m 48s) (67700 67%) 0.3424\n",
      "18m 28s (- 8m 46s) (67800 67%) 0.4269\n",
      "18m 30s (- 8m 44s) (67900 67%) 0.3273\n",
      "18m 31s (- 8m 43s) (68000 68%) 0.2833\n",
      "18m 33s (- 8m 41s) (68100 68%) 0.4201\n",
      "18m 34s (- 8m 39s) (68200 68%) 0.3026\n",
      "18m 36s (- 8m 38s) (68300 68%) 0.3636\n",
      "18m 37s (- 8m 36s) (68400 68%) 0.3290\n",
      "18m 38s (- 8m 34s) (68500 68%) 0.2992\n",
      "18m 40s (- 8m 32s) (68600 68%) 0.3235\n",
      "18m 41s (- 8m 30s) (68700 68%) 0.3074\n",
      "18m 42s (- 8m 29s) (68800 68%) 0.3098\n",
      "18m 44s (- 8m 27s) (68900 68%) 0.2804\n",
      "18m 45s (- 8m 25s) (69000 69%) 0.4090\n",
      "18m 47s (- 8m 24s) (69100 69%) 0.3613\n",
      "18m 48s (- 8m 22s) (69200 69%) 0.3054\n",
      "18m 50s (- 8m 20s) (69300 69%) 0.2721\n",
      "18m 51s (- 8m 18s) (69400 69%) 0.3703\n",
      "18m 52s (- 8m 17s) (69500 69%) 0.2979\n",
      "18m 54s (- 8m 15s) (69600 69%) 0.2637\n",
      "18m 55s (- 8m 13s) (69700 69%) 0.3045\n",
      "18m 57s (- 8m 11s) (69800 69%) 0.3791\n",
      "18m 58s (- 8m 10s) (69900 69%) 0.3328\n",
      "18m 59s (- 8m 8s) (70000 70%) 0.3084\n",
      "19m 1s (- 8m 6s) (70100 70%) 0.3369\n",
      "19m 2s (- 8m 4s) (70200 70%) 0.3083\n",
      "19m 3s (- 8m 3s) (70300 70%) 0.3298\n",
      "19m 5s (- 8m 1s) (70400 70%) 0.4316\n",
      "19m 6s (- 7m 59s) (70500 70%) 0.3377\n",
      "19m 8s (- 7m 58s) (70600 70%) 0.2838\n",
      "19m 9s (- 7m 56s) (70700 70%) 0.2453\n",
      "19m 10s (- 7m 54s) (70800 70%) 0.4067\n",
      "19m 12s (- 7m 52s) (70900 70%) 0.3239\n",
      "19m 13s (- 7m 51s) (71000 71%) 0.2737\n",
      "19m 14s (- 7m 49s) (71100 71%) 0.3338\n",
      "19m 16s (- 7m 47s) (71200 71%) 0.4143\n",
      "19m 17s (- 7m 46s) (71300 71%) 0.3546\n",
      "19m 19s (- 7m 44s) (71400 71%) 0.3961\n",
      "19m 21s (- 7m 43s) (71500 71%) 0.2510\n",
      "19m 23s (- 7m 41s) (71600 71%) 0.3530\n",
      "19m 25s (- 7m 39s) (71700 71%) 0.3648\n",
      "19m 26s (- 7m 38s) (71800 71%) 0.3798\n",
      "19m 28s (- 7m 36s) (71900 71%) 0.3087\n",
      "19m 30s (- 7m 35s) (72000 72%) 0.2946\n",
      "19m 31s (- 7m 33s) (72100 72%) 0.4361\n",
      "19m 33s (- 7m 31s) (72200 72%) 0.3155\n",
      "19m 34s (- 7m 29s) (72300 72%) 0.3142\n",
      "19m 35s (- 7m 28s) (72400 72%) 0.3353\n",
      "19m 37s (- 7m 26s) (72500 72%) 0.3943\n",
      "19m 38s (- 7m 24s) (72600 72%) 0.4531\n",
      "19m 40s (- 7m 23s) (72700 72%) 0.2983\n",
      "19m 41s (- 7m 21s) (72800 72%) 0.2428\n",
      "19m 42s (- 7m 19s) (72900 72%) 0.2866\n",
      "19m 44s (- 7m 18s) (73000 73%) 0.4235\n",
      "19m 46s (- 7m 16s) (73100 73%) 0.2879\n",
      "19m 47s (- 7m 14s) (73200 73%) 0.3394\n",
      "19m 49s (- 7m 13s) (73300 73%) 0.3379\n",
      "19m 50s (- 7m 11s) (73400 73%) 0.2896\n",
      "19m 52s (- 7m 9s) (73500 73%) 0.2934\n",
      "19m 53s (- 7m 8s) (73600 73%) 0.3447\n",
      "19m 54s (- 7m 6s) (73700 73%) 0.3831\n",
      "19m 56s (- 7m 4s) (73800 73%) 0.2514\n",
      "19m 58s (- 7m 3s) (73900 73%) 0.2933\n",
      "19m 59s (- 7m 1s) (74000 74%) 0.3655\n",
      "20m 0s (- 6m 59s) (74100 74%) 0.3964\n",
      "20m 2s (- 6m 58s) (74200 74%) 0.2941\n",
      "20m 3s (- 6m 56s) (74300 74%) 0.4246\n",
      "20m 5s (- 6m 54s) (74400 74%) 0.4149\n",
      "20m 6s (- 6m 52s) (74500 74%) 0.2434\n",
      "20m 7s (- 6m 51s) (74600 74%) 0.3340\n",
      "20m 9s (- 6m 49s) (74700 74%) 0.3382\n",
      "20m 10s (- 6m 47s) (74800 74%) 0.3390\n",
      "20m 12s (- 6m 46s) (74900 74%) 0.2387\n",
      "20m 13s (- 6m 44s) (75000 75%) 0.3691\n",
      "20m 14s (- 6m 42s) (75100 75%) 0.3547\n",
      "20m 16s (- 6m 41s) (75200 75%) 0.3235\n",
      "20m 17s (- 6m 39s) (75300 75%) 0.3069\n",
      "20m 19s (- 6m 37s) (75400 75%) 0.3069\n",
      "20m 20s (- 6m 36s) (75500 75%) 0.3960\n",
      "20m 21s (- 6m 34s) (75600 75%) 0.3247\n",
      "20m 23s (- 6m 32s) (75700 75%) 0.3267\n",
      "20m 24s (- 6m 31s) (75800 75%) 0.2987\n",
      "20m 26s (- 6m 29s) (75900 75%) 0.3272\n",
      "20m 27s (- 6m 27s) (76000 76%) 0.3609\n",
      "20m 28s (- 6m 25s) (76100 76%) 0.3519\n",
      "20m 30s (- 6m 24s) (76200 76%) 0.4187\n",
      "20m 31s (- 6m 22s) (76300 76%) 0.2398\n",
      "20m 32s (- 6m 20s) (76400 76%) 0.2855\n",
      "20m 34s (- 6m 19s) (76500 76%) 0.2838\n",
      "20m 36s (- 6m 17s) (76600 76%) 0.3289\n",
      "20m 37s (- 6m 15s) (76700 76%) 0.2951\n",
      "20m 38s (- 6m 14s) (76800 76%) 0.3260\n",
      "20m 40s (- 6m 12s) (76900 76%) 0.3674\n",
      "20m 41s (- 6m 10s) (77000 77%) 0.3517\n",
      "20m 42s (- 6m 9s) (77100 77%) 0.2877\n",
      "20m 44s (- 6m 7s) (77200 77%) 0.2731\n",
      "20m 45s (- 6m 5s) (77300 77%) 0.3055\n",
      "20m 47s (- 6m 4s) (77400 77%) 0.3911\n",
      "20m 48s (- 6m 2s) (77500 77%) 0.4451\n",
      "20m 50s (- 6m 0s) (77600 77%) 0.3494\n",
      "20m 51s (- 5m 59s) (77700 77%) 0.3234\n",
      "20m 53s (- 5m 57s) (77800 77%) 0.3147\n",
      "20m 54s (- 5m 56s) (77900 77%) 0.3488\n",
      "20m 56s (- 5m 54s) (78000 78%) 0.2998\n",
      "20m 57s (- 5m 52s) (78100 78%) 0.3419\n",
      "20m 59s (- 5m 50s) (78200 78%) 0.3452\n",
      "21m 0s (- 5m 49s) (78300 78%) 0.3259\n",
      "21m 1s (- 5m 47s) (78400 78%) 0.2698\n",
      "21m 3s (- 5m 45s) (78500 78%) 0.3546\n",
      "21m 4s (- 5m 44s) (78600 78%) 0.2911\n",
      "21m 5s (- 5m 42s) (78700 78%) 0.3328\n",
      "21m 7s (- 5m 40s) (78800 78%) 0.3933\n",
      "21m 8s (- 5m 39s) (78900 78%) 0.2662\n",
      "21m 10s (- 5m 37s) (79000 79%) 0.2588\n",
      "21m 11s (- 5m 35s) (79100 79%) 0.4203\n",
      "21m 13s (- 5m 34s) (79200 79%) 0.2284\n",
      "21m 14s (- 5m 32s) (79300 79%) 0.3349\n",
      "21m 15s (- 5m 30s) (79400 79%) 0.3542\n",
      "21m 17s (- 5m 29s) (79500 79%) 0.3074\n",
      "21m 18s (- 5m 27s) (79600 79%) 0.3967\n",
      "21m 20s (- 5m 26s) (79700 79%) 0.2864\n",
      "21m 21s (- 5m 24s) (79800 79%) 0.2869\n",
      "21m 23s (- 5m 22s) (79900 79%) 0.3457\n",
      "21m 24s (- 5m 21s) (80000 80%) 0.3484\n",
      "21m 26s (- 5m 19s) (80100 80%) 0.2078\n",
      "21m 27s (- 5m 17s) (80200 80%) 0.3494\n",
      "21m 29s (- 5m 16s) (80300 80%) 0.2858\n",
      "21m 30s (- 5m 14s) (80400 80%) 0.4039\n",
      "21m 32s (- 5m 12s) (80500 80%) 0.2820\n",
      "21m 33s (- 5m 11s) (80600 80%) 0.3993\n",
      "21m 34s (- 5m 9s) (80700 80%) 0.3017\n",
      "21m 36s (- 5m 8s) (80800 80%) 0.2769\n",
      "21m 37s (- 5m 6s) (80900 80%) 0.3440\n",
      "21m 39s (- 5m 4s) (81000 81%) 0.3642\n",
      "21m 41s (- 5m 3s) (81100 81%) 0.3183\n",
      "21m 42s (- 5m 1s) (81200 81%) 0.2502\n",
      "21m 44s (- 4m 59s) (81300 81%) 0.3935\n",
      "21m 45s (- 4m 58s) (81400 81%) 0.3263\n",
      "21m 46s (- 4m 56s) (81500 81%) 0.2479\n",
      "21m 48s (- 4m 55s) (81600 81%) 0.2496\n",
      "21m 49s (- 4m 53s) (81700 81%) 0.3828\n",
      "21m 51s (- 4m 51s) (81800 81%) 0.2591\n",
      "21m 52s (- 4m 50s) (81900 81%) 0.2889\n",
      "21m 54s (- 4m 48s) (82000 82%) 0.2962\n",
      "21m 55s (- 4m 46s) (82100 82%) 0.3940\n",
      "21m 56s (- 4m 45s) (82200 82%) 0.2736\n",
      "21m 58s (- 4m 43s) (82300 82%) 0.2828\n",
      "21m 59s (- 4m 41s) (82400 82%) 0.3355\n",
      "22m 0s (- 4m 40s) (82500 82%) 0.2957\n",
      "22m 2s (- 4m 38s) (82600 82%) 0.3697\n",
      "22m 3s (- 4m 36s) (82700 82%) 0.3605\n",
      "22m 4s (- 4m 35s) (82800 82%) 0.3050\n",
      "22m 6s (- 4m 33s) (82900 82%) 0.2752\n",
      "22m 7s (- 4m 31s) (83000 83%) 0.2699\n",
      "22m 9s (- 4m 30s) (83100 83%) 0.3240\n",
      "22m 10s (- 4m 28s) (83200 83%) 0.3933\n",
      "22m 11s (- 4m 27s) (83300 83%) 0.3745\n",
      "22m 13s (- 4m 25s) (83400 83%) 0.3157\n",
      "22m 14s (- 4m 23s) (83500 83%) 0.3000\n",
      "22m 16s (- 4m 22s) (83600 83%) 0.4046\n",
      "22m 17s (- 4m 20s) (83700 83%) 0.4106\n",
      "22m 18s (- 4m 18s) (83800 83%) 0.3909\n",
      "22m 20s (- 4m 17s) (83900 83%) 0.3154\n",
      "22m 21s (- 4m 15s) (84000 84%) 0.2037\n",
      "22m 22s (- 4m 13s) (84100 84%) 0.3309\n",
      "22m 24s (- 4m 12s) (84200 84%) 0.3029\n",
      "22m 25s (- 4m 10s) (84300 84%) 0.2207\n",
      "22m 27s (- 4m 9s) (84400 84%) 0.3200\n",
      "22m 28s (- 4m 7s) (84500 84%) 0.4497\n",
      "22m 29s (- 4m 5s) (84600 84%) 0.4105\n",
      "22m 31s (- 4m 4s) (84700 84%) 0.3731\n",
      "22m 32s (- 4m 2s) (84800 84%) 0.3350\n",
      "22m 33s (- 4m 0s) (84900 84%) 0.3331\n",
      "22m 35s (- 3m 59s) (85000 85%) 0.3469\n",
      "22m 36s (- 3m 57s) (85100 85%) 0.3720\n",
      "22m 38s (- 3m 55s) (85200 85%) 0.3347\n",
      "22m 39s (- 3m 54s) (85300 85%) 0.2662\n",
      "22m 40s (- 3m 52s) (85400 85%) 0.3285\n",
      "22m 42s (- 3m 51s) (85500 85%) 0.3465\n",
      "22m 44s (- 3m 49s) (85600 85%) 0.3315\n",
      "22m 45s (- 3m 47s) (85700 85%) 0.3178\n",
      "22m 47s (- 3m 46s) (85800 85%) 0.3655\n",
      "22m 48s (- 3m 44s) (85900 85%) 0.3506\n",
      "22m 50s (- 3m 43s) (86000 86%) 0.3047\n",
      "22m 51s (- 3m 41s) (86100 86%) 0.3314\n",
      "22m 52s (- 3m 39s) (86200 86%) 0.3605\n",
      "22m 54s (- 3m 38s) (86300 86%) 0.3128\n",
      "22m 55s (- 3m 36s) (86400 86%) 0.3359\n",
      "22m 57s (- 3m 34s) (86500 86%) 0.2873\n",
      "22m 58s (- 3m 33s) (86600 86%) 0.2442\n",
      "22m 59s (- 3m 31s) (86700 86%) 0.2834\n",
      "23m 1s (- 3m 30s) (86800 86%) 0.3470\n",
      "23m 2s (- 3m 28s) (86900 86%) 0.3030\n",
      "23m 3s (- 3m 26s) (87000 87%) 0.3230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23m 5s (- 3m 25s) (87100 87%) 0.2709\n",
      "23m 7s (- 3m 23s) (87200 87%) 0.3178\n",
      "23m 8s (- 3m 22s) (87300 87%) 0.3869\n",
      "23m 9s (- 3m 20s) (87400 87%) 0.3430\n",
      "23m 11s (- 3m 18s) (87500 87%) 0.3198\n",
      "23m 12s (- 3m 17s) (87600 87%) 0.2793\n",
      "23m 14s (- 3m 15s) (87700 87%) 0.3079\n",
      "23m 15s (- 3m 13s) (87800 87%) 0.2248\n",
      "23m 17s (- 3m 12s) (87900 87%) 0.3841\n",
      "23m 18s (- 3m 10s) (88000 88%) 0.2698\n",
      "23m 19s (- 3m 9s) (88100 88%) 0.3175\n",
      "23m 21s (- 3m 7s) (88200 88%) 0.2413\n",
      "23m 22s (- 3m 5s) (88300 88%) 0.3461\n",
      "23m 24s (- 3m 4s) (88400 88%) 0.3644\n",
      "23m 25s (- 3m 2s) (88500 88%) 0.2558\n",
      "23m 26s (- 3m 1s) (88600 88%) 0.3850\n",
      "23m 28s (- 2m 59s) (88700 88%) 0.2992\n",
      "23m 29s (- 2m 57s) (88800 88%) 0.3290\n",
      "23m 30s (- 2m 56s) (88900 88%) 0.2952\n",
      "23m 32s (- 2m 54s) (89000 89%) 0.2499\n",
      "23m 33s (- 2m 52s) (89100 89%) 0.2693\n",
      "23m 35s (- 2m 51s) (89200 89%) 0.2924\n",
      "23m 36s (- 2m 49s) (89300 89%) 0.3234\n",
      "23m 37s (- 2m 48s) (89400 89%) 0.3541\n",
      "23m 39s (- 2m 46s) (89500 89%) 0.3426\n",
      "23m 40s (- 2m 44s) (89600 89%) 0.2987\n",
      "23m 41s (- 2m 43s) (89700 89%) 0.3189\n",
      "23m 43s (- 2m 41s) (89800 89%) 0.3324\n",
      "23m 44s (- 2m 40s) (89900 89%) 0.3033\n",
      "23m 46s (- 2m 38s) (90000 90%) 0.2583\n",
      "23m 47s (- 2m 36s) (90100 90%) 0.2915\n",
      "23m 48s (- 2m 35s) (90200 90%) 0.3372\n",
      "23m 50s (- 2m 33s) (90300 90%) 0.2608\n",
      "23m 51s (- 2m 32s) (90400 90%) 0.3688\n",
      "23m 53s (- 2m 30s) (90500 90%) 0.3950\n",
      "23m 54s (- 2m 28s) (90600 90%) 0.3699\n",
      "23m 55s (- 2m 27s) (90700 90%) 0.2454\n",
      "23m 57s (- 2m 25s) (90800 90%) 0.2725\n",
      "23m 58s (- 2m 24s) (90900 90%) 0.2912\n",
      "24m 0s (- 2m 22s) (91000 91%) 0.2846\n",
      "24m 1s (- 2m 20s) (91100 91%) 0.2898\n",
      "24m 3s (- 2m 19s) (91200 91%) 0.3005\n",
      "24m 4s (- 2m 17s) (91300 91%) 0.3094\n",
      "24m 6s (- 2m 16s) (91400 91%) 0.3072\n",
      "24m 7s (- 2m 14s) (91500 91%) 0.3695\n",
      "24m 8s (- 2m 12s) (91600 91%) 0.2872\n",
      "24m 10s (- 2m 11s) (91700 91%) 0.3682\n",
      "24m 11s (- 2m 9s) (91800 91%) 0.3460\n",
      "24m 13s (- 2m 8s) (91900 91%) 0.3395\n",
      "24m 14s (- 2m 6s) (92000 92%) 0.2550\n",
      "24m 15s (- 2m 4s) (92100 92%) 0.2979\n",
      "24m 17s (- 2m 3s) (92200 92%) 0.3501\n",
      "24m 18s (- 2m 1s) (92300 92%) 0.3234\n",
      "24m 20s (- 2m 0s) (92400 92%) 0.2784\n",
      "24m 21s (- 1m 58s) (92500 92%) 0.2639\n",
      "24m 22s (- 1m 56s) (92600 92%) 0.4279\n",
      "24m 24s (- 1m 55s) (92700 92%) 0.4199\n",
      "24m 25s (- 1m 53s) (92800 92%) 0.2755\n",
      "24m 27s (- 1m 52s) (92900 92%) 0.3217\n",
      "24m 28s (- 1m 50s) (93000 93%) 0.3295\n",
      "24m 30s (- 1m 48s) (93100 93%) 0.1751\n",
      "24m 31s (- 1m 47s) (93200 93%) 0.3357\n",
      "24m 33s (- 1m 45s) (93300 93%) 0.2522\n",
      "24m 34s (- 1m 44s) (93400 93%) 0.3181\n",
      "24m 36s (- 1m 42s) (93500 93%) 0.3949\n",
      "24m 37s (- 1m 41s) (93600 93%) 0.3687\n",
      "24m 38s (- 1m 39s) (93700 93%) 0.2583\n",
      "24m 40s (- 1m 37s) (93800 93%) 0.3184\n",
      "24m 41s (- 1m 36s) (93900 93%) 0.3141\n",
      "24m 42s (- 1m 34s) (94000 94%) 0.3724\n",
      "24m 44s (- 1m 33s) (94100 94%) 0.3606\n",
      "24m 45s (- 1m 31s) (94200 94%) 0.3068\n",
      "24m 46s (- 1m 29s) (94300 94%) 0.4022\n",
      "24m 48s (- 1m 28s) (94400 94%) 0.3453\n",
      "24m 49s (- 1m 26s) (94500 94%) 0.3971\n",
      "24m 50s (- 1m 25s) (94600 94%) 0.2718\n",
      "24m 52s (- 1m 23s) (94700 94%) 0.3515\n",
      "24m 53s (- 1m 21s) (94800 94%) 0.3721\n",
      "24m 55s (- 1m 20s) (94900 94%) 0.2791\n",
      "24m 56s (- 1m 18s) (95000 95%) 0.3001\n",
      "24m 57s (- 1m 17s) (95100 95%) 0.3901\n",
      "24m 59s (- 1m 15s) (95200 95%) 0.2782\n",
      "25m 0s (- 1m 13s) (95300 95%) 0.2850\n",
      "25m 1s (- 1m 12s) (95400 95%) 0.3096\n",
      "25m 3s (- 1m 10s) (95500 95%) 0.3414\n",
      "25m 4s (- 1m 9s) (95600 95%) 0.3250\n",
      "25m 5s (- 1m 7s) (95700 95%) 0.4214\n",
      "25m 7s (- 1m 6s) (95800 95%) 0.2497\n",
      "25m 8s (- 1m 4s) (95900 95%) 0.3269\n",
      "25m 9s (- 1m 2s) (96000 96%) 0.2807\n",
      "25m 11s (- 1m 1s) (96100 96%) 0.3260\n",
      "25m 12s (- 0m 59s) (96200 96%) 0.3185\n",
      "25m 14s (- 0m 58s) (96300 96%) 0.3572\n",
      "25m 15s (- 0m 56s) (96400 96%) 0.3735\n",
      "25m 16s (- 0m 55s) (96500 96%) 0.3104\n",
      "25m 18s (- 0m 53s) (96600 96%) 0.3098\n",
      "25m 19s (- 0m 51s) (96700 96%) 0.2943\n",
      "25m 21s (- 0m 50s) (96800 96%) 0.3265\n",
      "25m 22s (- 0m 48s) (96900 96%) 0.3771\n",
      "25m 23s (- 0m 47s) (97000 97%) 0.2483\n",
      "25m 25s (- 0m 45s) (97100 97%) 0.3392\n",
      "25m 26s (- 0m 43s) (97200 97%) 0.3990\n",
      "25m 27s (- 0m 42s) (97300 97%) 0.2216\n",
      "25m 29s (- 0m 40s) (97400 97%) 0.2781\n",
      "25m 30s (- 0m 39s) (97500 97%) 0.3399\n",
      "25m 32s (- 0m 37s) (97600 97%) 0.2405\n",
      "25m 33s (- 0m 36s) (97700 97%) 0.3586\n",
      "25m 35s (- 0m 34s) (97800 97%) 0.3004\n",
      "25m 36s (- 0m 32s) (97900 97%) 0.2682\n",
      "25m 37s (- 0m 31s) (98000 98%) 0.4192\n",
      "25m 39s (- 0m 29s) (98100 98%) 0.3324\n",
      "25m 40s (- 0m 28s) (98200 98%) 0.3701\n",
      "25m 41s (- 0m 26s) (98300 98%) 0.4393\n",
      "25m 43s (- 0m 25s) (98400 98%) 0.2280\n",
      "25m 44s (- 0m 23s) (98500 98%) 0.3177\n",
      "25m 46s (- 0m 21s) (98600 98%) 0.2777\n",
      "25m 47s (- 0m 20s) (98700 98%) 0.2781\n",
      "25m 48s (- 0m 18s) (98800 98%) 0.2771\n",
      "25m 50s (- 0m 17s) (98900 98%) 0.3117\n",
      "25m 52s (- 0m 15s) (99000 99%) 0.3590\n",
      "25m 54s (- 0m 14s) (99100 99%) 0.3969\n",
      "25m 55s (- 0m 12s) (99200 99%) 0.3903\n",
      "25m 57s (- 0m 10s) (99300 99%) 0.3228\n",
      "25m 58s (- 0m 9s) (99400 99%) 0.2634\n",
      "25m 59s (- 0m 7s) (99500 99%) 0.3284\n",
      "26m 1s (- 0m 6s) (99600 99%) 0.2660\n",
      "26m 2s (- 0m 4s) (99700 99%) 0.3458\n",
      "26m 3s (- 0m 3s) (99800 99%) 0.2606\n",
      "26m 5s (- 0m 1s) (99900 99%) 0.3192\n",
      "26m 6s (- 0m 0s) (100000 100%) 0.2848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b397cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b146e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 20\n",
    "batches = 100000 # In this case, the PyTorch train_per_epoch() and train() code is using batch_size=1\n",
    "hidden_size = 100\n",
    "\n",
    "my_encoder = EncoderRNN(len(singlish_vocab), hidden_size)\n",
    "my_decoder = AttnDecoderRNN(hidden_size, len(english_vocab))\n",
    "\n",
    "if use_cuda:\n",
    "    my_encoder = my_encoder.cuda()\n",
    "    my_decoder = my_decoder.cuda()\n",
    "\n",
    "\n",
    "# Load the pre-trained model with teacher forcing.\n",
    "\"\"\"\n",
    "with open('encoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_encoder = pickle.load(fin)\n",
    "    \n",
    "with open('decoder_attention_100_100000_0.5.pkl', 'rb') as fin:\n",
    "    my_decoder = pickle.load(fin)\n",
    "\"\"\"\n",
    "\n",
    "# Or train a new model; un-comment the following lines\n",
    "\n",
    "train(my_encoder, my_decoder, batches, print_every=100)\n",
    "# In Python >= 3.6\n",
    "with open(f'encoder_attention_{hidden_size}_{batches}_teacher_forcing_ratio.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_encoder, fout)\n",
    "with open(f'decoder_attention_{hidden_size}_{batches}_teacher_forcing_ratio.pkl', 'wb') as fout:\n",
    "    pickle.dump(my_decoder, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "def translator(encoder, decoder, input_variable, max_length=MAX_LENGTH):\n",
    "    # The length of the input.\n",
    "    input_length = input_variable.size()[0]\n",
    "    # For each sentence, initilize the hidden states with zeros.\n",
    "    encoder_hidden = encoder.initialize_hidden_states()\n",
    "    # Initialize the encoder outputs. \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "    # Iterate through the input words.\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "    # Initialize the decoder with the start symbol <s>.\n",
    "    decoder_input = Variable(torch.LongTensor([[START_IDX]])) \n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    # Use the last encoder hidden state as the first decoder's hidden state.\n",
    "    decoder_hidden = encoder_hidden\n",
    "    # Keep a list of the decoded words.\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Iterate through the decoder states.\n",
    "    for di in range(max_length):\n",
    "        # Very similar to how the training works.\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, \n",
    "                                                                    decoder_hidden,\n",
    "                                                                    encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == END_IDX:\n",
    "            decoded_words.append(END_IDX)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(ni)\n",
    "        # Replace the new decoder input for the next state \n",
    "        # with the top guess of this state.\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    return decoded_words, decoder_attentions[:di + 1]\n",
    "\n",
    "    \n",
    "def translate(kopi_order):\n",
    "    output_words, _ = translator(my_encoder, my_decoder, variable_from_sent(kopi_order, singlish_vocab))\n",
    "    output_sentence = [english_vocab[i] for i in output_words[1:output_words.index(1)]]\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tea with evaporated milk and sugar'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tea with more sugar'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh ga dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot tea with evaporated milk and more sugar'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh c ga dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iced tea with evaporated milk and more sugar'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh c ga dai peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tea with less sugar'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh o siew dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heaviest , purest version of tea with no water added at all to the initial brew'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh tiloh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iced milo'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('tak kiu peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strong iced milo'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('tak kiu gau peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soya bean milk mixed with grass jelly'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('michael jackson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iced strong iced with condensed milk and sugar'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('michael jackson peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iced tea with condensed'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('teh siew dai peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strong iced coffee of coffee'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi peng gau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strong iced coffee with condensed milk'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi gau peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strong black coffee with sugar'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi o gau peng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot black coffee with more coffee powder and lesser sugar'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi o gau siew dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot coffee with condensed milk and lesser coffee powder and lesser sugar'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('kopi dinosaur gau siew dai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
